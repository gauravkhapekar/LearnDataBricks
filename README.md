# LearnDataBricks

# PySpark COVID-19 Data Analysis ğŸš€

This repository contains resources for learning and applying **PySpark** on real-world data.  
The main goal is to demonstrate how to perform distributed data processing and analysis using **Apache Spark**, leveraging a publicly available COVID-19 dataset.

## ğŸ“ Project Structure

![Files Overview](./b502fb83-4e47-48bf-970c-64833321d87e.png)

- `Training_for_PySpark.ipynb`: A Google Colab notebook with hands-on exercises and tutorials on PySpark â€” from creating RDDs and DataFrames to performing transformations and actions.
- `owid-covid-data.zip`: A ZIP file containing the **Our World in Data COVID-19 dataset**. This will be used for data exploration and transformation tasks inside the notebook.

## ğŸ“¦ How to Use

1. Clone the repository or upload it into Google Colab.
2. Unzip `owid-covid-data.zip` and locate the CSV file inside.
3. Run the `Training_for_PySpark.ipynb` notebook step-by-step.
4. Learn how to:
   - Load and parse CSV data using Spark
   - Perform DataFrame operations
   - Filter, group, and aggregate large datasets
   - Handle real-world use cases in a scalable way

## ğŸ’¡ Prerequisites

- Python 3.x
- Apache Spark
- PySpark (`pip install pyspark`)
- Google Colab (optional but recommended)

## ğŸ“Š Dataset Info

**Source**: [Our World in Data - COVID-19 Dataset](https://ourworldindata.org/covid-deaths)  
The dataset includes global COVID-19 case counts, deaths, testing metrics, and vaccination data.

## ğŸ”¥ Learning Outcomes

- Understand PySpark fundamentals (RDDs, DataFrames, and SQL)
- Apply distributed processing on large datasets
- Practice real-life data transformation use cases
- Build a scalable data pipeline for COVID-19 analysis

## ğŸ§‘â€ğŸ’» Author

Created and maintained by **Gaurav Khapekar**  
Feel free to fork, star â­, or submit pull requests.

---

ğŸ“¬ For queries, contact: `your.email@example.com`

